# 智能体状态管理

## 一、状态管理概述

### 1. 什么是智能体状态管理

智能体状态管理是指智能体对其内部状态和外部环境状态的感知、存储、更新和使用的过程。它是智能体实现复杂任务和持续学习的基础，使智能体能够：

- 记住过去的交互历史
- 跟踪任务执行进度
- 适应环境变化
- 积累知识和经验
- 做出更明智的决策

### 2. 状态的类型

智能体的状态可以分为以下几类：

- **内部状态**：智能体自身的状态，如当前任务、执行进度、健康状况等
- **外部状态**：智能体感知到的外部环境状态
- **短期状态**：临时存储的状态，如当前对话内容、临时变量等
- **长期状态**：长期存储的状态，如知识库、经验教训等
- **隐式状态**：不直接存储但可以通过其他状态推导出来的状态
- **显式状态**：直接存储和管理的状态

### 3. 状态管理的重要性

- **连续性**：保持任务执行的连续性
- **上下文理解**：理解对话和任务的上下文
- **学习能力**：通过状态积累实现学习
- **适应性**：适应环境和任务的变化
- **协作能力**：支持多智能体协作

## 二、状态的表示与存储

### 1. 状态的表示方法

- **键值对**：简单的键值存储，适合存储结构化数据
- **对象模型**：使用面向对象的方式表示状态
- **图结构**：使用图来表示状态之间的关系
- **向量表示**：使用向量嵌入表示非结构化状态
- **结构化数据**：使用JSON、XML等格式表示状态

### 2. 状态的存储方式

- **内存存储**：适合短期状态，访问速度快
- **文件存储**：适合长期状态，持久化存储
- **数据库存储**：适合大量结构化状态
- **向量数据库**：适合非结构化状态的相似性检索
- **分布式存储**：适合大规模状态管理

## 三、基于LangChain 1.0的状态管理

### 1. LangChain 1.0的状态管理组件

LangChain 1.0提供了多种状态管理组件：

- **RunnablePassthrough**：传递状态不变
- **RunnableLambda**：使用自定义函数处理状态
- **RunnableParallel**：并行处理多个状态
- **RunnableSequence**：按顺序处理状态
- **Memory**：管理对话历史和状态

### 2. 对话历史管理

```python
from langchain_openai import ChatOpenAI
from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder
from langchain_core.runnables.history import RunnableWithMessageHistory
from langchain_core.chat_history import InMemoryChatMessageHistory

# 初始化LLM
llm = ChatOpenAI(model="gpt-3.5-turbo")

# 创建提示模板，包含消息历史占位符
prompt = ChatPromptTemplate.from_messages([
    ("system", "你是一个 helpful 的智能助手，能够记住之前的对话内容。"),
    MessagesPlaceholder(variable_name="chat_history"),
    ("user", "{input}")
])

# 创建链
chain = prompt | llm

# 创建内存存储
session_store = {}

def get_session_history(session_id: str) -> InMemoryChatMessageHistory:
    """获取会话历史"""
    if session_id not in session_store:
        session_store[session_id] = InMemoryChatMessageHistory()
    return session_store[session_id]

# 创建带消息历史的链
chain_with_history = RunnableWithMessageHistory(
    chain,
    get_session_history,
    input_messages_key="input",
    history_messages_key="chat_history"
)

# 测试对话历史管理
if __name__ == "__main__":
    session_id = "user_123"
    
    # 第一轮对话
    response1 = chain_with_history.invoke(
        {"input": "你好，我叫小明"},
        config={"configurable": {"session_id": session_id}}
    )
    print(f"智能体：{response1.content}")
    
    # 第二轮对话，智能体应该记住用户的名字
    response2 = chain_with_history.invoke(
        {"input": "我叫什么名字？"},
        config={"configurable": {"session_id": session_id}}
    )
    print(f"智能体：{response2.content}")
    
    # 第三轮对话
    response3 = chain_with_history.invoke(
        {"input": "我想学习智能体开发"},
        config={"configurable": {"session_id": session_id}}
    )
    print(f"智能体：{response3.content}")
    
    # 查看会话历史
    history = get_session_history(session_id)
    print(f"\n会话历史：")
    for message in history.messages:
        print(f"  {message.type}: {message.content}")
```

### 3. 自定义状态管理

```python
from langchain_openai import ChatOpenAI
from langchain_core.prompts import ChatPromptTemplate
from langchain_core.runnables import RunnablePassthrough
from langchain_core.runnables.base import RunnableConfig

# 初始化LLM
llm = ChatOpenAI(model="gpt-3.5-turbo")

# 自定义状态管理类
class CustomStateManager:
    def __init__(self):
        self.state_store = {}
    
    def get_state(self, session_id: str) -> dict:
        """获取状态"""
        if session_id not in self.state_store:
            self.state_store[session_id] = {
                "user_name": None,
                "topic": None,
                "session_count": 0,
                "last_interaction": None
            }
        return self.state_store[session_id]
    
    def update_state(self, session_id: str, updates: dict) -> dict:
        """更新状态"""
        state = self.get_state(session_id)
        state.update(updates)
        state["session_count"] += 1
        state["last_interaction"] = self._get_current_time()
        return state
    
    def _get_current_time(self):
        """获取当前时间"""
        from datetime import datetime
        return datetime.now().isoformat()

# 创建状态管理器实例
state_manager = CustomStateManager()

# 创建提示模板
prompt = ChatPromptTemplate.from_messages([
    ("system", "你是一个 helpful 的智能助手。用户信息：{user_info}"),
    ("user", "{input}")
])

# 自定义状态处理函数
def process_state(input_dict: dict, config: RunnableConfig) -> dict:
    """处理状态"""
    # 获取会话ID
    session_id = config.get("configurable", {}).get("session_id", "default")
    
    # 获取当前状态
    state = state_manager.get_state(session_id)
    
    # 从用户输入中提取信息更新状态
    input_text = input_dict["input"]
    if "我叫" in input_text:
        # 提取用户名
        user_name = input_text.split("我叫")[-1].strip()
        state_manager.update_state(session_id, {"user_name": user_name})
    
    if any(topic in input_text.lower() for topic in ["智能体", "开发", "学习"]):
        state_manager.update_state(session_id, {"topic": "智能体开发"})
    
    # 获取更新后的状态
    updated_state = state_manager.get_state(session_id)
    
    # 构建用户信息字符串
    user_info_parts = []
    if updated_state["user_name"]:
        user_info_parts.append(f"姓名：{updated_state['user_name']}")
    if updated_state["topic"]:
        user_info_parts.append(f"感兴趣的话题：{updated_state['topic']}")
    user_info = "; ".join(user_info_parts) if user_info_parts else "无"
    
    # 返回包含状态信息的字典
    return {
        **input_dict,
        "user_info": user_info,
        "session_state": updated_state
    }

# 创建链
chain = RunnablePassthrough.assign(
    processed_state=process_state
) | prompt | llm

# 测试自定义状态管理
if __name__ == "__main__":
    session_id = "user_456"
    
    # 第一轮对话
    print("=== 第一轮对话 ===")
    response1 = chain.invoke(
        {"input": "你好，我叫小红"},
        config={"configurable": {"session_id": session_id}}
    )
    print(f"智能体：{response1.content}")
    
    # 第二轮对话
    print("\n=== 第二轮对话 ===")
    response2 = chain.invoke(
        {"input": "我想学习智能体开发"},
        config={"configurable": {"session_id": session_id}}
    )
    print(f"智能体：{response2.content}")
    
    # 第三轮对话
    print("\n=== 第三轮对话 ===")
    response3 = chain.invoke(
        {"input": "你能告诉我学习路径吗？"},
        config={"configurable": {"session_id": session_id}}
    )
    print(f"智能体：{response3.content}")
    
    # 查看最终状态
    final_state = state_manager.get_state(session_id)
    print(f"\n最终状态：{final_state}")
```

## 四、记忆系统设计

### 1. 记忆的类型

- **感官记忆**：短暂存储感官输入
- **短期记忆（工作记忆）**：存储当前处理的信息
- **长期记忆**：存储长期知识和经验
  - **陈述性记忆**：事实和事件的记忆
  - **程序性记忆**：技能和习惯的记忆

### 2. 基于向量数据库的长期记忆

```python
from langchain_openai import ChatOpenAI, OpenAIEmbeddings
from langchain_chroma import Chroma
from langchain_core.prompts import ChatPromptTemplate
from langchain_core.runnables import RunnablePassthrough
from langchain_core.output_parsers import StrOutputParser

# 初始化组件
llm = ChatOpenAI(model="gpt-3.5-turbo")
embeddings = OpenAIEmbeddings()

# 创建向量数据库
vectorstore = Chroma(embedding_function=embeddings, persist_directory="./memory_db")

# 示例知识
knowledge_base = [
    "智能体（Agent）是指能够感知环境、做出决策并执行行动以实现目标的实体。",
    "LangChain是一个用于构建基于LLM的应用程序的框架。",
    "自主规划是智能体根据目标和环境信息，自主制定行动方案的能力。",
    "工具使用是智能体能够自主选择和调用外部工具或API来完成任务的能力。",
    "状态管理是指智能体对其内部状态和外部环境状态的感知、存储、更新和使用的过程。"
]

# 将知识添加到向量数据库
vectorstore.add_texts(knowledge_base)

# 创建检索器
retriever = vectorstore.as_retriever(search_kwargs={"k": 3})

# 创建提示模板
prompt = ChatPromptTemplate.from_template(
    """请根据提供的上下文回答用户问题。如果上下文没有相关信息，可以根据你的知识回答。
    
    上下文：{context}
    
    用户问题：{input}
    
    回答：
    """
)

# 创建链
chain = {
    "context": RunnablePassthrough.assign(query=lambda x: x["input"]) | retriever,
    "input": RunnablePassthrough()
} | prompt | llm | StrOutputParser()

# 测试长期记忆
if __name__ == "__main__":
    questions = [
        "什么是智能体？",
        "LangChain是什么？",
        "智能体的核心能力有哪些？"
    ]
    
    for question in questions:
        print(f"\n用户问题：{question}")
        result = chain.invoke({"input": question})
        print(f"智能体回答：{result}")
    
    # 添加新的知识
    new_knowledge = [
        "多智能体系统是由多个智能体组成的系统，智能体之间可以相互交互和协作。",
        "MCP（Multi-Agent Communication Protocol）是一种多智能体通信协议。"
    ]
    vectorstore.add_texts(new_knowledge)
    print("\n=== 添加新知识后 ===")
    
    # 测试新添加的知识
    new_questions = [
        "什么是多智能体系统？",
        "MCP是什么？"
    ]
    
    for question in new_questions:
        print(f"\n用户问题：{question}")
        result = chain.invoke({"input": question})
        print(f"智能体回答：{result}")
```

### 3. 记忆的检索与更新

```python
from langchain_openai import OpenAIEmbeddings
from langchain_chroma import Chroma

class AdvancedMemorySystem:
    def __init__(self, persist_directory="./advanced_memory_db"):
        self.embeddings = OpenAIEmbeddings()
        self.vectorstore = Chroma(
            embedding_function=self.embeddings,
            persist_directory=persist_directory
        )
        self.memory_index = 0
    
    def add_memory(self, content: str, metadata=None):
        """添加记忆"""
        if metadata is None:
            metadata = {}
        
        # 添加默认元数据
        metadata.update({
            "memory_id": f"mem_{self.memory_index}",
            "timestamp": self._get_current_time(),
            "type": "general"
        })
        
        # 添加到向量数据库
        self.vectorstore.add_texts([content], metadatas=[metadata])
        self.memory_index += 1
        
        return metadata["memory_id"]
    
    def retrieve_memories(self, query: str, k=5, filters=None):
        """检索记忆"""
        search_kwargs = {"k": k}
        if filters:
            search_kwargs["filter"] = filters
        
        docs = self.vectorstore.similarity_search(query, **search_kwargs)
        
        memories = []
        for doc in docs:
            memories.append({
                "content": doc.page_content,
                "metadata": doc.metadata
            })
        
        return memories
    
    def update_memory(self, memory_id: str, new_content: str):
        """更新记忆"""
        # 注意：Chroma DB不支持直接更新，需要先删除再添加
        # 1. 查找要更新的记忆
        memories = self.retrieve_memories(memory_id, k=1, filters={"memory_id": memory_id})
        if not memories:
            return False
        
        # 2. 删除旧记忆
        old_metadata = memories[0]["metadata"]
        self.vectorstore.delete(ids=[old_metadata["memory_id"]])
        
        # 3. 添加新记忆，保留原记忆ID
        self.vectorstore.add_texts([new_content], metadatas=[old_metadata])
        return True
    
    def delete_memory(self, memory_id: str):
        """删除记忆"""
        result = self.vectorstore.delete(ids=[memory_id])
        return result.get("deleted", 0) > 0
    
    def list_memories(self, limit=10):
        """列出所有记忆"""
        # 注意：Chroma DB没有直接列出所有文档的API，这里使用空查询检索
        docs = self.vectorstore.similarity_search("", k=limit)
        
        memories = []
        for doc in docs:
            memories.append({
                "content": doc.page_content,
                "metadata": doc.metadata
            })
        
        return memories
    
    def _get_current_time(self):
        """获取当前时间"""
        from datetime import datetime
        return datetime.now().isoformat()

# 测试高级记忆系统
if __name__ == "__main__":
    memory_system = AdvancedMemorySystem()
    
    # 添加记忆
    mem_id1 = memory_system.add_memory(
        "智能体开发的核心组件包括感知模块、决策模块、执行模块和记忆模块。",
        metadata={"type": "knowledge", "domain": "智能体开发"}
    )
    print(f"添加记忆成功，ID：{mem_id1}")
    
    mem_id2 = memory_system.add_memory(
        "LangChain 1.0提供了强大的状态管理和记忆组件。",
        metadata={"type": "knowledge", "domain": "LangChain"}
    )
    print(f"添加记忆成功，ID：{mem_id2}")
    
    # 检索记忆
    print("\n=== 检索相关记忆 ===")
    memories = memory_system.retrieve_memories("智能体开发", k=2)
    for mem in memories:
        print(f"记忆ID：{mem['metadata']['memory_id']}，内容：{mem['content']}")
    
    # 更新记忆
    print("\n=== 更新记忆 ===")
    success = memory_system.update_memory(
        mem_id1,
        "智能体开发的核心组件包括感知模块、决策模块、执行模块、记忆模块和通信模块。"
    )
    print(f"更新记忆成功：{success}")
    
    # 验证更新
    updated_memories = memory_system.retrieve_memories("智能体开发", k=1)
    print(f"更新后的记忆：{updated_memories[0]['content']}")
    
    # 列出所有记忆
    print("\n=== 列出所有记忆 ===")
    all_memories = memory_system.list_memories()
    for mem in all_memories:
        print(f"记忆ID：{mem['metadata']['memory_id']}，类型：{mem['metadata']['type']}，内容：{mem['content']}")
```

## 四、状态管理的最佳实践

### 1. 状态设计原则

- **模块化**：将状态划分为独立的模块
- **分层**：采用分层架构管理状态
- **最小化**：只存储必要的状态
- **标准化**：使用标准的状态表示格式
- **版本控制**：对状态进行版本管理

### 2. 性能优化

- **缓存**：频繁访问的状态使用缓存
- **异步处理**：异步加载和更新状态
- **批量操作**：批量处理状态更新
- **索引优化**：为状态添加合适的索引
- **惰性加载**：按需加载状态

### 3. 安全性考虑

- **加密存储**：敏感状态加密存储
- **访问控制**：限制状态的访问权限
- **审计日志**：记录状态的访问和修改
- **数据备份**：定期备份状态数据
- **防篡改**：防止状态被恶意篡改

## 五、状态管理的高级技术

### 1. 状态预测与推理

```python
from langchain_openai import ChatOpenAI
from langchain_core.prompts import ChatPromptTemplate
from langchain_core.output_parsers import JsonOutputParser

# 初始化LLM
llm = ChatOpenAI(model="gpt-3.5-turbo")

# 创建状态预测提示模板
prompt = ChatPromptTemplate.from_messages([
    ("system", "你是一个状态预测专家，能够根据历史状态预测未来状态。请输出JSON格式结果。"),
    ("user", "请根据以下历史状态预测用户的下一步状态：
    
    历史状态：
    {history}
    
    当前状态：
    {current_state}
    
    输出格式：
    {{"predicted_state": "预测的状态描述", "confidence": 置信度（0-1之间的数字）, "reasoning": "预测理由"}}
    ")
])

# 创建链
chain = prompt | llm | JsonOutputParser()

# 测试状态预测
if __name__ == "__main__":
    # 示例状态数据
    history = [
        "用户搜索了智能体开发相关内容",
        "用户阅读了LangChain框架文档",
        "用户开始学习自主规划技术"
    ]
    
    current_state = "用户正在学习工具使用技术"
    
    result = chain.invoke({
        "history": "\n".join(history),
        "current_state": current_state
    })
    
    print(f"状态预测结果：")
    print(f"  预测状态：{result['predicted_state']}")
    print(f"  置信度：{result['confidence']}")
    print(f"  预测理由：{result['reasoning']}")
```

### 2. 状态可视化

```python
import json
import matplotlib.pyplot as plt
from collections import Counter

# 假设我们有以下状态数据
state_data = [
    {"timestamp": "2026-01-01T10:00:00", "state": "idle"},
    {"timestamp": "2026-01-01T10:05:00", "state": "working"},
    {"timestamp": "2026-01-01T10:20:00", "state": "idle"},
    {"timestamp": "2026-01-01T10:30:00", "state": "working"},
    {"timestamp": "2026-01-01T11:00:00", "state": "error"},
    {"timestamp": "2026-01-01T11:05:00", "state": "idle"},
    {"timestamp": "2026-01-01T11:10:00", "state": "working"},
    {"timestamp": "2026-01-01T11:30:00", "state": "idle"}
]

# 状态可视化函数
def visualize_states(states):
    """可视化状态分布"""
    # 统计各状态出现次数
    state_counts = Counter(state["state"] for state in states)
    
    # 准备数据
    labels = list(state_counts.keys())
    sizes = list(state_counts.values())
    colors = ['gold', 'lightgreen', 'lightcoral']
    explode = (0.1, 0, 0)  # 突出显示第一个状态
    
    # 创建饼图
    plt.figure(figsize=(10, 6))
    
    # 绘制饼图
    plt.pie(sizes, explode=explode, labels=labels, colors=colors,
            autopct='%1.1f%%', shadow=True, startangle=140)
    
    plt.axis('equal')  # 保证饼图是正圆形
    plt.title('智能体状态分布')
    
    # 保存图表
    plt.savefig('agent_state_distribution.png')
    print("状态分布图已保存为 agent_state_distribution.png")

# 测试状态可视化
if __name__ == "__main__":
    visualize_states(state_data)
    print("状态可视化完成")
```

## 六、状态管理的完整案例

### 1. 任务状态管理

```python
from langchain_openai import ChatOpenAI
from langchain_core.prompts import ChatPromptTemplate
from langchain_core.runnables import RunnablePassthrough
from langchain_core.output_parsers import StrOutputParser

# 任务状态定义
class TaskState:
    def __init__(self):
        self.tasks = {}
        self.task_counter = 0
    
    def create_task(self, description: str, priority: str = "medium"):
        """创建任务"""
        task_id = f"task_{self.task_counter}"
        self.task_counter += 1
        
        self.tasks[task_id] = {
            "task_id": task_id,
            "description": description,
            "priority": priority,
            "status": "pending",  # pending, in_progress, completed, failed
            "created_at": self._get_current_time(),
            "updated_at": self._get_current_time(),
            "progress": 0,
            "results": []
        }
        
        return task_id
    
    def update_task_status(self, task_id: str, status: str, progress: int = None):
        """更新任务状态"""
        if task_id in self.tasks:
            self.tasks[task_id]["status"] = status
            if progress is not None:
                self.tasks[task_id]["progress"] = min(100, max(0, progress))
            self.tasks[task_id]["updated_at"] = self._get_current_time()
            return True
        return False
    
    def add_task_result(self, task_id: str, result: str):
        """添加任务结果"""
        if task_id in self.tasks:
            self.tasks[task_id]["results"].append({
                "result": result,
                "timestamp": self._get_current_time()
            })
            self.tasks[task_id]["updated_at"] = self._get_current_time()
            return True
        return False
    
    def get_task(self, task_id: str):
        """获取任务"""
        return self.tasks.get(task_id)
    
    def list_tasks(self, status: str = None):
        """列出任务"""
        if status:
            return [task for task in self.tasks.values() if task["status"] == status]
        return list(self.tasks.values())
    
    def _get_current_time(self):
        """获取当前时间"""
        from datetime import datetime
        return datetime.now().isoformat()

# 创建任务状态管理器
task_state = TaskState()

# 初始化LLM
llm = ChatOpenAI(model="gpt-3.5-turbo")

# 创建提示模板
prompt = ChatPromptTemplate.from_template(
    """请根据用户请求创建或管理任务。
    
    当前任务列表：{tasks}
    
    用户请求：{input}
    
    回答格式：
    1. 首先说明你做了什么
    2. 然后列出当前的任务状态
    """
)

# 自定义任务处理函数
def process_task_request(input_dict):
    """处理任务请求"""
    input_text = input_dict["input"]
    
    # 创建任务
    if "创建任务" in input_text or "新建任务" in input_text:
        # 提取任务描述
        if "创建任务" in input_text:
            task_desc = input_text.split("创建任务")[-1].strip()
        else:
            task_desc = input_text.split("新建任务")[-1].strip()
        
        # 提取优先级
        priority = "medium"
        if any(p in input_text.lower() for p in ["高", "紧急"]):
            priority = "high"
        elif any(p in input_text.lower() for p in ["低", "不重要"]):
            priority = "low"
        
        # 创建任务
        task_id = task_state.create_task(task_desc, priority)
        input_dict["action"] = f"创建了任务：{task_id}"
    
    # 更新任务状态
    elif "开始任务" in input_text:
        # 提取任务ID
        task_id = input_text.split("开始任务")[-1].strip()
        task_state.update_task_status(task_id, "in_progress", progress=10)
        input_dict["action"] = f"开始了任务：{task_id}"
    
    elif "完成任务" in input_text:
        # 提取任务ID
        task_id = input_text.split("完成任务")[-1].strip()
        task_state.update_task_status(task_id, "completed", progress=100)
        input_dict["action"] = f"完成了任务：{task_id}"
    
    # 添加任务结果
    elif "添加结果" in input_text:
        # 简单提取任务ID和结果
        parts = input_text.split("添加结果")[-1].strip().split("，")
        if len(parts) >= 2:
            task_id = parts[0].strip()
            result = "，".join(parts[1:]).strip()
            task_state.add_task_result(task_id, result)
            input_dict["action"] = f"为任务 {task_id} 添加了结果"
    
    # 默认列出所有任务
    tasks = task_state.list_tasks()
    input_dict["tasks"] = "\n".join([
        f"任务ID：{task['task_id']}，描述：{task['description']}，状态：{task['status']}，优先级：{task['priority']}，进度：{task['progress']}%"
        for task in tasks
    ])
    
    return input_dict

# 创建链
chain = RunnablePassthrough.assign(
    processed=process_task_request
) | prompt | llm | StrOutputParser()

# 测试任务状态管理
if __name__ == "__main__":
    requests = [
        "创建任务：学习智能体状态管理",
        "创建高优先级任务：完成状态管理案例",
        "开始任务 task_0",
        "添加结果 task_0，学习了状态管理的基本概念",
        "完成任务 task_0",
        "列出所有任务"
    ]
    
    for request in requests:
        print(f"\n=== 用户请求：{request} ===")
        result = chain.invoke({"input": request})
        print(f"=== 智能体回复：{result} ===")
```

## 七、总结

智能体状态管理是智能体开发中的核心能力之一，它使智能体能够记住过去的交互、跟踪任务进度、适应环境变化并积累知识。通过本章节的学习，你应该掌握：

- 状态管理的基本概念和重要性
- 状态的表示和存储方法
- 基于LangChain 1.0的状态管理实现
- 对话历史管理
- 长期记忆系统设计
- 状态管理的最佳实践
- 状态管理的高级技术
- 完整的状态管理案例

在实际开发中，你可以根据具体需求设计和实现合适的状态管理系统，结合智能体的其他能力，构建功能强大、适应性强的智能体应用。
