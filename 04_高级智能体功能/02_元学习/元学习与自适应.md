# 元学习与自适应

## 一、元学习概述

### 1. 什么是元学习

元学习（Meta-Learning）是智能体学习如何学习的能力，使智能体能够：

- 快速适应新任务和新环境
- 从有限的经验中学习
- 自我改进和持续优化
- 识别和应用最佳学习策略

### 2. 元学习的重要性

- **快速适应**：在新任务上仅需少量样本即可达到良好性能
- **持续学习**：不断积累知识，避免灾难性遗忘
- **自主优化**：自动调整自身参数和策略
- **泛化能力**：将学习到的知识迁移到新场景

### 3. 元学习的应用场景

- **少样本学习**：数据稀缺的场景
- **跨领域迁移**：将知识从一个领域迁移到另一个领域
- **在线学习**：实时适应环境变化
- **终身学习**：持续积累和更新知识

## 二、元学习方法

### 1. 基于优化的元学习

- **MAML (Model-Agnostic Meta-Learning)**：学习模型的初始化参数，使其在新任务上经过少量梯度更新后能达到最佳性能
- **Reptile**：通过多次优化不同任务，逐渐向所有任务的最优解移动
- **Meta-SGD**：学习每个参数的学习率和初始化值

### 2. 基于记忆的元学习

- **Siamese Networks**：通过比较输入的相似性进行分类
- **Prototypical Networks**：计算每个类别的原型表示，然后基于距离进行分类
- **Matching Networks**：使用注意力机制处理支持集和查询集

### 3. 基于度量的元学习

- **Relation Networks**：学习一个深度距离度量来比较输入
- **Graph Neural Networks**：将任务表示为图结构，通过消息传递进行学习

### 4. 基于策略的元学习

- **RL^2**：将强化学习算法本身作为学习对象
- **Meta-Q-Learning**：学习Q-learning算法的参数
- **Learning to Optimize**：学习优化算法的策略

## 三、智能体的自适应能力

### 1. 什么是自适应

自适应是智能体根据环境变化和经验反馈自动调整行为和策略的能力，包括：

- **环境适应**：根据环境变化调整行为
- **任务适应**：根据任务需求调整策略
- **用户适应**：根据用户偏好调整交互方式
- **自我适应**：根据自身表现调整内部参数

### 2. 自适应的层次

| 层次 | 描述 | 示例 |
|------|------|------|
| 反应式适应 | 基于当前输入的即时调整 | 调整回答风格以匹配用户语气 |
| 认知适应 | 基于经验和知识的调整 | 根据历史对话调整问题解决策略 |
| 元认知适应 | 基于自身认知过程的调整 | 识别学习瓶颈并调整学习策略 |
| 进化适应 | 长期的结构和能力调整 | 开发新的解决问题的方法 |

### 3. 自适应的实现机制

- **反馈循环**：收集反馈并用于调整
- **参数调整**：调整模型参数和超参数
- **策略选择**：选择最佳的行动策略
- **知识更新**：更新内部知识表示

## 四、基于LangChain 1.0的元学习实现

### 1. 基础元学习框架

```python
import os
import json
from typing import Dict, Any, List, Optional
from dotenv import load_dotenv
from langchain_openai import ChatOpenAI
from langchain_core.prompts import ChatPromptTemplate
from langchain_core.runnables import RunnablePassthrough
from langchain_core.output_parsers import StrOutputParser, JsonOutputParser

# 加载环境变量
load_dotenv()

class MetaLearner:
    """元学习器"""
    
    def __init__(self, model_name: str = "gpt-3.5-turbo"):
        self.llm = ChatOpenAI(model=model_name, temperature=0.7)
        self.experience_store = []
        self.meta_knowledge = {
            "best_practices": [],
            "common_mistakes": [],
            "task_strategies": {}
        }
    
    def learn_from_experience(self, experience: Dict[str, Any]):
        """从经验中学习
        
        Args:
            experience: 经验数据，包含任务、策略、结果、反馈等
        """
        # 存储经验
        self.experience_store.append(experience)
        
        # 分析经验，提取元知识
        self._analyze_experience(experience)
    
    def _analyze_experience(self, experience: Dict[str, Any]):
        """分析经验数据
        
        Args:
            experience: 经验数据
        """
        # 提取任务类型
        task_type = experience.get("task_type", "general")
        
        # 提取策略和结果
        strategy = experience.get("strategy", {})
        result = experience.get("result", {})
        feedback = experience.get("feedback", {})
        
        # 更新任务策略
        if task_type not in self.meta_knowledge["task_strategies"]:
            self.meta_knowledge["task_strategies"][task_type] = []
        
        self.meta_knowledge["task_strategies"][task_type].append({
            "strategy": strategy,
            "result": result,
            "feedback": feedback,
            "timestamp": experience.get("timestamp", "")
        })
        
        # 提取最佳实践和常见错误
        if feedback.get("success", False):
            self.meta_knowledge["best_practices"].append({
                "task_type": task_type,
                "strategy": strategy,
                "reason": feedback.get("reason", "")
            })
        else:
            self.meta_knowledge["common_mistakes"].append({
                "task_type": task_type,
                "strategy": strategy,
                "error": feedback.get("error", ""),
                "correction": feedback.get("correction", "")
            })
    
    def get_meta_knowledge(self) -> Dict[str, Any]:
        """获取元知识
        
        Returns:
            元知识字典
        """
        return self.meta_knowledge
    
    def save_meta_knowledge(self, path: str = "./meta_knowledge.json"):
        """保存元知识
        
        Args:
            path: 保存路径
        """
        with open(path, "w", encoding="utf-8") as f:
            json.dump(self.meta_knowledge, f, ensure_ascii=False, indent=2)
    
    def load_meta_knowledge(self, path: str = "./meta_knowledge.json"):
        """加载元知识
        
        Args:
            path: 加载路径
        """
        if os.path.exists(path):
            with open(path, "r", encoding="utf-8") as f:
                self.meta_knowledge = json.load(f)
    
    def adapt_strategy(self, task: str, task_type: str = "general") -> Dict[str, Any]:
        """根据元知识调整策略
        
        Args:
            task: 任务描述
            task_type: 任务类型
        
        Returns:
            调整后的策略
        """
        # 分析任务
        task_analysis = self._analyze_task(task)
        
        # 获取相关元知识
        relevant_strategies = self.meta_knowledge["task_strategies"].get(task_type, [])
        relevant_best_practices = [p for p in self.meta_knowledge["best_practices"] if p["task_type"] == task_type]
        relevant_mistakes = [m for m in self.meta_knowledge["common_mistakes"] if m["task_type"] == task_type]
        
        # 生成自适应策略
        strategy = self._generate_strategy(
            task,
            task_analysis,
            relevant_strategies,
            relevant_best_practices,
            relevant_mistakes
        )
        
        return strategy
    
    def _analyze_task(self, task: str) -> Dict[str, Any]:
        """分析任务
        
        Args:
            task: 任务描述
        
        Returns:
            任务分析结果
        """
        # 创建任务分析提示
        prompt = ChatPromptTemplate.from_messages([
            ("system", "你是一个任务分析专家，请分析以下任务的性质、要求和难度。"),
            ("user", "请分析以下任务：{task}")
        ])
        
        # 创建分析链
        chain = prompt | self.llm | JsonOutputParser()
        
        # 执行分析
        try:
            return chain.invoke({"task": task})
        except Exception as e:
            return {
                "type": "general",
                "difficulty": "medium",
                "requirements": [],
                "estimated_time": "unknown"
            }
    
    def _generate_strategy(self, task: str, task_analysis: Dict[str, Any],
                          relevant_strategies: List[Dict[str, Any]],
                          relevant_best_practices: List[Dict[str, Any]],
                          relevant_mistakes: List[Dict[str, Any]]) -> Dict[str, Any]:
        """生成自适应策略
        
        Args:
            task: 任务描述
            task_analysis: 任务分析结果
            relevant_strategies: 相关策略
            relevant_best_practices: 相关最佳实践
            relevant_mistakes: 相关常见错误
        
        Returns:
            生成的策略
        """
        # 构建策略生成提示
        prompt = ChatPromptTemplate.from_messages([
            ("system", "你是一个策略生成专家，请根据任务分析和相关经验生成最佳策略。"),
            ("user", "请根据以下信息为任务生成最佳策略：\n" 
             "任务：{task}\n" 
             "任务分析：{task_analysis}\n" 
             "相关策略：{relevant_strategies}\n" 
             "最佳实践：{relevant_best_practices}\n" 
             "常见错误：{relevant_mistakes}")
        ])
        
        # 创建策略生成链
        chain = prompt | self.llm | JsonOutputParser()
        
        # 执行策略生成
        try:
            return chain.invoke({
                "task": task,
                "task_analysis": json.dumps(task_analysis),
                "relevant_strategies": json.dumps(relevant_strategies[:3]),  # 只使用最近的3个策略
                "relevant_best_practices": json.dumps(relevant_best_practices[:3]),  # 只使用最近的3个最佳实践
                "relevant_mistakes": json.dumps(relevant_mistakes[:3])  # 只使用最近的3个常见错误
            })
        except Exception as e:
            return {
                "approach": "default",
                "steps": [],
                "considerations": []
            }
```

### 2. 自适应智能体实现

```python
from langchain_openai import ChatOpenAI
from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder
from langchain_core.runnables import RunnableWithMessageHistory
from langchain_core.chat_history import InMemoryChatMessageHistory
from langchain_core.output_parsers import StrOutputParser
from typing import Dict, Any, List, Optional
import time

# 会话存储
session_store = {}

def get_session_history(session_id: str) -> InMemoryChatMessageHistory:
    """获取会话历史"""
    if session_id not in session_store:
        session_store[session_id] = InMemoryChatMessageHistory()
    return session_store[session_id]

class AdaptiveAgent:
    """自适应智能体"""
    
    def __init__(self, name: str = "自适应智能体", model_name: str = "gpt-3.5-turbo"):
        self.name = name
        self.llm = ChatOpenAI(model=model_name, temperature=0.7)
        self.meta_learner = MetaLearner(model_name=model_name)
        
        # 创建基础提示模板
        self.base_prompt = ChatPromptTemplate.from_messages([
            ("system", "你是一个自适应智能体，能够根据经验和反馈不断改进。"),
            MessagesPlaceholder(variable_name="chat_history"),
            ("user", "{input}")
        ])
        
        # 创建带历史记录的链
        self.base_chain = self.base_prompt | self.llm | StrOutputParser()
        self.chain = RunnableWithMessageHistory(
            self.base_chain,
            get_session_history,
            input_messages_key="input",
            history_messages_key="chat_history"
        )
        
        # 存储任务历史
        self.task_history = []
    
    def invoke(self, input: str, session_id: str = None, task_type: str = "general") -> Dict[str, Any]:
        """调用智能体
        
        Args:
            input: 用户输入
            session_id: 会话ID
            task_type: 任务类型
        
        Returns:
            智能体的响应和策略
        """
        if not session_id:
            session_id = self.name
        
        # 记录开始时间
        start_time = time.time()
        
        # 生成自适应策略
        strategy = self.meta_learner.adapt_strategy(input, task_type)
        
        # 创建增强提示
        enhanced_prompt = ChatPromptTemplate.from_messages([
            ("system", "你是一个自适应智能体，能够根据经验和反馈不断改进。请参考以下策略执行任务：\n{strategy}"),
            MessagesPlaceholder(variable_name="chat_history"),
            ("user", "{input}")
        ])
        
        # 创建增强链
        enhanced_chain = enhanced_prompt | self.llm | StrOutputParser()
        enhanced_runnable = RunnableWithMessageHistory(
            enhanced_chain,
            get_session_history,
            input_messages_key="input",
            history_messages_key="chat_history"
        )
        
        # 执行增强链
        response = enhanced_runnable.invoke(
            {"input": input, "strategy": str(strategy)},
            config={"configurable": {"session_id": session_id}}
        )
        
        # 记录结束时间
        end_time = time.time()
        execution_time = end_time - start_time
        
        # 存储任务历史
        task_record = {
            "input": input,
            "response": response,
            "strategy": strategy,
            "task_type": task_type,
            "execution_time": execution_time,
            "timestamp": time.strftime("%Y-%m-%d %H:%M:%S"),
            "session_id": session_id
        }
        self.task_history.append(task_record)
        
        return {
            "response": response,
            "strategy": strategy,
            "execution_time": execution_time
        }
    
    def provide_feedback(self, task_index: int, success: bool, reason: str = "",
                        error: str = "", correction: str = ""):
        """提供反馈
        
        Args:
            task_index: 任务历史的索引
            success: 是否成功
            reason: 成功的原因
            error: 错误信息
            correction: 修正建议
        """
        if 0 <= task_index < len(self.task_history):
            task_record = self.task_history[task_index]
            
            # 构建反馈
            feedback = {
                "success": success,
                "reason": reason,
                "error": error,
                "correction": correction,
                "timestamp": time.strftime("%Y-%m-%d %H:%M:%S")
            }
            
            # 构建经验数据
            experience = {
                "task": task_record["input"],
                "task_type": task_record["task_type"],
                "strategy": task_record["strategy"],
                "result": {
                    "response": task_record["response"],
                    "execution_time": task_record["execution_time"]
                },
                "feedback": feedback,
                "timestamp": task_record["timestamp"]
            }
            
            # 学习经验
            self.meta_learner.learn_from_experience(experience)
            
            # 更新任务记录
            task_record["feedback"] = feedback
    
    def get_meta_knowledge(self) -> Dict[str, Any]:
        """获取元知识
        
        Returns:
            元知识字典
        """
        return self.meta_learner.get_meta_knowledge()
    
    def save_meta_knowledge(self, path: str = "./meta_knowledge.json"):
        """保存元知识
        
        Args:
            path: 保存路径
        """
        self.meta_learner.save_meta_knowledge(path)
    
    def load_meta_knowledge(self, path: str = "./meta_knowledge.json"):
        """加载元知识
        
        Args:
            path: 加载路径
        """
        self.meta_learner.load_meta_knowledge(path)
    
    def get_task_history(self) -> List[Dict[str, Any]]:
        """获取任务历史
        
        Returns:
            任务历史列表
        """
        return self.task_history
```

## 五、持续学习机制

### 1. 持续学习的挑战

- **灾难性遗忘**：学习新知识时忘记旧知识
- **数据分布偏移**：新数据与训练数据分布不同
- **计算资源限制**：持续学习需要大量计算资源
- **概念漂移**：目标概念随时间变化

### 2. 持续学习的策略

- **回放策略**：存储和回放旧数据
  - **经验回放**：随机回放存储的经验
  - **优先级回放**：基于重要性回放经验
  - **生成式回放**：使用生成模型回放旧数据

- **正则化策略**：保护重要参数
  - **EWC (Elastic Weight Consolidation)**：为重要参数添加正则化项
  - **L2正则化**：限制参数变化
  - **蒸馏策略**：使用旧模型的知识指导新模型

- **架构策略**：动态调整模型架构
  - **渐进式网络**：添加新的神经元和连接
  - **动态架构**：根据任务动态调整网络结构
  - **模块化网络**：为不同任务使用不同的模块

### 3. 持续学习的实现

```python
import os
import json
import time
from typing import Dict, Any, List, Optional
from langchain_openai import ChatOpenAI
from langchain_core.prompts import ChatPromptTemplate
from langchain_core.runnables import RunnablePassthrough
from langchain_core.output_parsers import StrOutputParser, JsonOutputParser

class ContinuousLearner:
    """持续学习器"""
    
    def __init__(self, model_name: str = "gpt-3.5-turbo", memory_size: int = 1000):
        self.llm = ChatOpenAI(model=model_name, temperature=0.7)
        self.memory_size = memory_size
        self.experience_memory = []
        self.knowledge_base = {}
        self.learning_rate = 0.1
    
    def add_experience(self, experience: Dict[str, Any]):
        """添加经验
        
        Args:
            experience: 经验数据
        """
        # 添加时间戳
        experience["timestamp"] = time.strftime("%Y-%m-%d %H:%M:%S")
        
        # 添加到经验记忆
        self.experience_memory.append(experience)
        
        # 限制记忆大小
        if len(self.experience_memory) > self.memory_size:
            self.experience_memory = self.experience_memory[-self.memory_size:]
        
        # 立即学习
        self.learn_from_experience(experience)
    
    def learn_from_experience(self, experience: Dict[str, Any]):
        """从经验中学习
        
        Args:
            experience: 经验数据
        """
        # 提取关键信息
        task_type = experience.get("task_type", "general")
        task = experience.get("task", "")
        response = experience.get("response", "")
        feedback = experience.get("feedback", {})
        
        # 更新知识库
        if task_type not in self.knowledge_base:
            self.knowledge_base[task_type] = {
                "examples": [],
                "rules": [],
                "common_mistakes": [],
                "best_practices": []
            }
        
        # 添加示例
        self.knowledge_base[task_type]["examples"].append({
            "task": task,
            "response": response,
            "feedback": feedback
        })
        
        # 提取规则和最佳实践
        if feedback.get("success", False):
            # 提取成功规则
            rule = self._extract_rule(task, response, feedback)
            if rule:
                self.knowledge_base[task_type]["best_practices"].append(rule)
        else:
            # 提取常见错误
            mistake = self._extract_mistake(task, response, feedback)
            if mistake:
                self.knowledge_base[task_type]["common_mistakes"].append(mistake)
    
    def _extract_rule(self, task: str, response: str, feedback: Dict[str, Any]) -> Optional[Dict[str, Any]]:
        """从成功经验中提取规则
        
        Args:
            task: 任务
            response: 响应
            feedback: 反馈
        
        Returns:
            提取的规则
        """
        # 创建规则提取提示
        prompt = ChatPromptTemplate.from_messages([
            ("system", "你是一个规则提取专家，请从以下成功案例中提取通用规则。"),
            ("user", "任务：{task}\n响应：{response}\n成功原因：{reason}")
        ])
        
        # 创建提取链
        chain = prompt | self.llm | JsonOutputParser()
        
        # 执行提取
        try:
            return chain.invoke({
                "task": task,
                "response": response,
                "reason": feedback.get("reason", "")
            })
        except Exception as e:
            return None
    
    def _extract_mistake(self, task: str, response: str, feedback: Dict[str, Any]) -> Optional[Dict[str, Any]]:
        """从失败经验中提取错误模式
        
        Args:
            task: 任务
            response: 响应
            feedback: 反馈
        
        Returns:
            提取的错误模式
        """
        # 创建错误提取提示
        prompt = ChatPromptTemplate.from_messages([
            ("system", "你是一个错误分析专家，请从以下失败案例中提取错误模式和修正建议。"),
            ("user", "任务：{task}\n响应：{response}\n错误：{error}\n修正建议：{correction}")
        ])
        
        # 创建提取链
        chain = prompt | self.llm | JsonOutputParser()
        
        # 执行提取
        try:
            return chain.invoke({
                "task": task,
                "response": response,
                "error": feedback.get("error", ""),
                "correction": feedback.get("correction", "")
            })
        except Exception as e:
            return None
    
    def get_knowledge(self, task_type: str = None) -> Dict[str, Any]:
        """获取知识库
        
        Args:
            task_type: 任务类型，None表示获取所有知识
        
        Returns:
            知识库
        """
        if task_type:
            return self.knowledge_base.get(task_type, {})
        return self.knowledge_base
    
    def save_knowledge(self, path: str = "./knowledge_base.json"):
        """保存知识库
        
        Args:
            path: 保存路径
        """
        with open(path, "w", encoding="utf-8") as f:
            json.dump(self.knowledge_base, f, ensure_ascii=False, indent=2)
    
    def load_knowledge(self, path: str = "./knowledge_base.json"):
        """加载知识库
        
        Args:
            path: 加载路径
        """
        if os.path.exists(path):
            with open(path, "r", encoding="utf-8") as f:
                self.knowledge_base = json.load(f)
    
    def adapt(self, task: str, task_type: str = "general") -> Dict[str, Any]:
        """根据知识库适应新任务
        
        Args:
            task: 新任务
            task_type: 任务类型
        
        Returns:
            适应策略
        """
        # 获取相关知识
        knowledge = self.get_knowledge(task_type)
        
        # 生成适应策略
        prompt = ChatPromptTemplate.from_messages([
            ("system", "你是一个适应策略生成专家，请根据以下知识库为新任务生成适应策略。"),
            ("user", "知识库：{knowledge}\n新任务：{task}")
        ])
        
        # 创建策略生成链
        chain = prompt | self.llm | JsonOutputParser()
        
        # 执行策略生成
        try:
            return chain.invoke({
                "knowledge": str(knowledge),
                "task": task
            })
        except Exception as e:
            return {
                "type": "default",
                "steps": [],
                "considerations": []
            }
```

## 四、智能体的自我评估

### 1. 什么是自我评估

自我评估是智能体对自身表现和能力进行评估的能力，包括：

- **表现评估**：评估任务完成的质量和效率
- **能力评估**：评估自身在不同领域的能力水平
- **知识评估**：评估自身知识的完整性和准确性
- **策略评估**：评估不同策略的有效性

### 2. 自我评估的方法

- **基于规则的评估**：使用预定义规则评估表现
- **基于反馈的评估**：基于用户反馈评估表现
- **基于比较的评估**：与历史表现或基准进行比较
- **元认知评估**：评估自身的认知过程和决策质量

### 3. 自我评估的实现

```python
import time
import json
from typing import Dict, Any, List, Optional
from langchain_openai import ChatOpenAI
from langchain_core.prompts import ChatPromptTemplate
from langchain_core.output_parsers import JsonOutputParser

class SelfEvaluator:
    """自我评估器"""
    
    def __init__(self, model_name: str = "gpt-3.5-turbo"):
        self.llm = ChatOpenAI(model=model_name, temperature=0.7)
        self.evaluation_history = []
    
    def evaluate_performance(self, task: str, response: str, 
                           expected: Optional[str] = None,
                           context: Optional[str] = None) -> Dict[str, Any]:
        """评估表现
        
        Args:
            task: 任务描述
            response: 智能体的响应
            expected: 期望的响应
            context: 上下文信息
        
        Returns:
            评估结果
        """
        # 创建评估提示
        prompt = ChatPromptTemplate.from_messages([
            ("system", "你是一个表现评估专家，请从准确性、完整性、相关性、清晰度和创新性五个维度评估智能体的表现。"),
            ("user", "任务：{task}\n智能体响应：{response}\n期望响应：{expected}\n上下文：{context}")
        ])
        
        # 创建评估链
        chain = prompt | self.llm | JsonOutputParser()
        
        # 执行评估
        try:
            evaluation = chain.invoke({
                "task": task,
                "response": response,
                "expected": expected or "",
                "context": context or ""
            })
        except Exception as e:
            evaluation = {
                "accuracy": 0.5,
                "completeness": 0.5,
                "relevance": 0.5,
                "clarity": 0.5,
                "innovation": 0.5,
                "overall": 0.5,
                "feedback": "评估失败"
            }
        
        # 添加时间戳和元数据
        evaluation["timestamp"] = time.strftime("%Y-%m-%d %H:%M:%S")
        evaluation["task"] = task
        evaluation["response"] = response
        
        # 存储评估历史
        self.evaluation_history.append(evaluation)
        
        return evaluation
    
    def evaluate_capability(self, domain: str, examples: List[Dict[str, Any]]) -> Dict[str, Any]:
        """评估能力
        
        Args:
            domain: 能力领域
            examples: 能力示例
        
        Returns:
            能力评估结果
        """
        # 创建能力评估提示
        prompt = ChatPromptTemplate.from_messages([
            ("system", "你是一个能力评估专家，请评估智能体在以下领域的能力水平。"),
            ("user", "领域：{domain}\n示例：{examples}")
        ])
        
        # 创建评估链
        chain = prompt | self.llm | JsonOutputParser()
        
        # 执行评估
        try:
            evaluation = chain.invoke({
                "domain": domain,
                "examples": json.dumps(examples)
            })
        except Exception as e:
            evaluation = {
                "domain": domain,
                "level": "intermediate",
                "strengths": [],
                "weaknesses": [],
                "recommendations": []
            }
        
        # 添加时间戳
        evaluation["timestamp"] = time.strftime("%Y-%m-%d %H:%M:%S")
        
        return evaluation
    
    def get_evaluation_history(self) -> List[Dict[str, Any]]:
        """获取评估历史
        
        Returns:
            评估历史
        """
        return self.evaluation_history
    
    def generate_improvement_plan(self, evaluations: List[Dict[str, Any]]) -> Dict[str, Any]:
        """生成改进计划
        
        Args:
            evaluations: 评估结果列表
        
        Returns:
            改进计划
        """
        # 创建改进计划生成提示
        prompt = ChatPromptTemplate.from_messages([
            ("system", "你是一个改进计划生成专家，请根据以下评估结果生成详细的改进计划。"),
            ("user", "评估结果：{evaluations}")
        ])
        
        # 创建改进计划生成链
        chain = prompt | self.llm | JsonOutputParser()
        
        # 执行改进计划生成
        try:
            return chain.invoke({
                "evaluations": json.dumps(evaluations)
            })
        except Exception as e:
            return {
                "goals": [],
                "actions": [],
                "timeline": "",
                "metrics": []
            }
```

## 五、案例：自适应智能体系统

### 1. 系统概述

构建一个能够自适应学习和改进的智能体系统，包含：

- 元学习模块：学习如何学习
- 自适应模块：根据环境调整策略
- 持续学习模块：不断积累知识
- 自我评估模块：评估自身表现

### 2. 实现代码

```python
import time
import json
from typing import Dict, Any, List, Optional
from langchain_openai import ChatOpenAI
from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder
from langchain_core.runnables import RunnableWithMessageHistory
from langchain_core.chat_history import InMemoryChatMessageHistory
from langchain_core.output_parsers import StrOutputParser

# 会话存储
session_store = {}

def get_session_history(session_id: str) -> InMemoryChatMessageHistory:
    """获取会话历史"""
    if session_id not in session_store:
        session_store[session_id] = InMemoryChatMessageHistory()
    return session_store[session_id]

# 导入之前定义的类
# from meta_learning import MetaLearner
# from continuous_learning import ContinuousLearner
# from self_evaluation import SelfEvaluator

class AdaptiveAgentSystem:
    """自适应智能体系统"""
    
    def __init__(self, name: str = "自适应智能体系统", model_name: str = "gpt-3.5-turbo"):
        self.name = name
        self.llm = ChatOpenAI(model=model_name, temperature=0.7)
        
        # 初始化各个模块
        self.meta_learner = MetaLearner(model_name=model_name)
        self.continuous_learner = ContinuousLearner(model_name=model_name)
        self.self_evaluator = SelfEvaluator(model_name=model_name)
        
        # 创建基础提示模板
        self.base_prompt = ChatPromptTemplate.from_messages([
            ("system", "你是一个自适应智能体系统，能够不断学习和改进。"),
            MessagesPlaceholder(variable_name="chat_history"),
            ("user", "{input}")
        ])
        
        # 创建带历史记录的链
        self.base_chain = self.base_prompt | self.llm | StrOutputParser()
        self.chain = RunnableWithMessageHistory(
            self.base_chain,
            get_session_history,
            input_messages_key="input",
            history_messages_key="chat_history"
        )
        
        # 存储系统历史
        self.system_history = []
    
    def invoke(self, input: str, session_id: str = None, task_type: str = "general") -> Dict[str, Any]:
        """调用智能体系统
        
        Args:
            input: 用户输入
            session_id: 会话ID
            task_type: 任务类型
        
        Returns:
            智能体的响应和相关信息
        """
        if not session_id:
            session_id = self.name
        
        # 记录开始时间
        start_time = time.time()
        
        # 1. 元学习：生成适应策略
        meta_strategy = self.meta_learner.adapt_strategy(input, task_type)
        
        # 2. 持续学习：适应新任务
        continuous_strategy = self.continuous_learner.adapt(input, task_type)
        
        # 3. 整合策略
        integrated_strategy = {
            "meta_strategy": meta_strategy,
            "continuous_strategy": continuous_strategy,
            "integrated_steps": self._integrate_strategies(meta_strategy, continuous_strategy)
        }
        
        # 4. 创建增强提示
        enhanced_prompt = ChatPromptTemplate.from_messages([
            ("system", "你是一个自适应智能体系统，能够不断学习和改进。请参考以下策略执行任务：\n{strategy}"),
            MessagesPlaceholder(variable_name="chat_history"),
            ("user", "{input}")
        ])
        
        # 5. 创建增强链
        enhanced_chain = enhanced_prompt | self.llm | StrOutputParser()
        enhanced_runnable = RunnableWithMessageHistory(
            enhanced_chain,
            get_session_history,
            input_messages_key="input",
            history_messages_key="chat_history"
        )
        
        # 6. 执行增强链
        response = enhanced_runnable.invoke(
            {"input": input, "strategy": str(integrated_strategy)},
            config={"configurable": {"session_id": session_id}}
        )
        
        # 7. 记录结束时间
        end_time = time.time()
        execution_time = end_time - start_time
        
        # 8. 自我评估
        evaluation = self.self_evaluator.evaluate_performance(input, response)
        
        # 9. 构建经验数据
        experience = {
            "task": input,
            "task_type": task_type,
            "response": response,
            "execution_time": execution_time,
            "evaluation": evaluation,
            "timestamp": time.strftime("%Y-%m-%d %H:%M:%S")
        }
        
        # 10. 更新学习模块
        self.meta_learner.learn_from_experience(experience)
        self.continuous_learner.add_experience(experience)
        
        # 11. 存储系统历史
        self.system_history.append(experience)
        
        # 12. 生成改进计划（如果评估分数低）
        improvement_plan = None
        if evaluation.get("overall", 0) < 0.7:
            improvement_plan = self.self_evaluator.generate_improvement_plan(
                [evaluation]
            )
        
        return {
            "response": response,
            "strategy": integrated_strategy,
            "evaluation": evaluation,
            "execution_time": execution_time,
            "improvement_plan": improvement_plan
        }
    
    def _integrate_strategies(self, meta_strategy: Dict[str, Any], 
                             continuous_strategy: Dict[str, Any]) -> List[str]:
        """整合多个策略
        
        Args:
            meta_strategy: 元学习策略
            continuous_strategy: 持续学习策略
        
        Returns:
            整合后的步骤
        """
        # 简单整合策略步骤
        steps = []
        
        # 添加元学习策略步骤
        if "steps" in meta_strategy:
            steps.extend(meta_strategy["steps"])
        
        # 添加持续学习策略步骤
        if "steps" in continuous_strategy:
            steps.extend(continuous_strategy["steps"])
        
        return steps
    
    def provide_feedback(self, session_id: str, task_index: int, 
                        success: bool, reason: str = "",
                        error: str = "", correction: str = ""):
        """提供反馈
        
        Args:
            session_id: 会话ID
            task_index: 任务索引
            success: 是否成功
            reason: 成功原因
            error: 错误信息
            correction: 修正建议
        """
        if 0 <= task_index < len(self.system_history):
            experience = self.system_history[task_index]
            
            # 更新反馈
            experience["feedback"] = {
                "success": success,
                "reason": reason,
                "error": error,
                "correction": correction,
                "timestamp": time.strftime("%Y-%m-%d %H:%M:%S")
            }
            
            # 更新学习模块
            self.meta_learner.learn_from_experience(experience)
            self.continuous_learner.add_experience(experience)
    
    def get_system_state(self) -> Dict[str, Any]:
        """获取系统状态
        
        Returns:
            系统状态
        """
        return {
            "meta_knowledge": self.meta_learner.get_meta_knowledge(),
            "continuous_knowledge": self.continuous_learner.get_knowledge(),
            "evaluation_history": self.self_evaluator.get_evaluation_history(),
            "system_history": self.system_history[-10:],  # 只返回最近10条记录
            "timestamp": time.strftime("%Y-%m-%d %H:%M:%S")
        }
    
    def save_system_state(self, path: str = "./system_state.json"):
        """保存系统状态
        
        Args:
            path: 保存路径
        """
        state = self.get_system_state()
        with open(path, "w", encoding="utf-8") as f:
            json.dump(state, f, ensure_ascii=False, indent=2)
    
    def load_system_state(self, path: str = "./system_state.json"):
        """加载系统状态
        
        Args:
            path: 加载路径
        """
        import os
        if os.path.exists(path):
            with open(path, "r", encoding="utf-8") as f:
                state = json.load(f)
            
            # 加载元知识
            if "meta_knowledge" in state:
                # 这里需要实现加载逻辑
                pass
            
            # 加载持续学习知识
            if "continuous_knowledge" in state:
                # 这里需要实现加载逻辑
                pass

# 测试自适应智能体系统
if __name__ == "__main__":
    # 创建系统
    system = AdaptiveAgentSystem()
    
    # 测试任务
    tasks = [
        "请解释什么是元学习",
        "如何实现智能体的自适应能力",
        "智能体持续学习的挑战是什么"
    ]
    
    for i, task in enumerate(tasks):
        print(f"\n=== 任务 {i+1}: {task} ===")
        
        # 调用系统
        result = system.invoke(task, task_type="education")
        
        # 打印结果
        print(f"响应: {result['response']}")
        print(f"评估: {result['evaluation']['overall']}")
        print(f"执行时间: {result['execution_time']:.2f}秒")
        
        # 提供反馈
        system.provide_feedback("test_session", i, True, "回答准确全面")
    
    # 保存系统状态
    system.save_system_state()
    print("\n系统状态已保存")
    
    # 获取系统状态
    state = system.get_system_state()
    print(f"\n系统历史记录数: {len(state['system_history'])}")
    print(f"元知识最佳实践数: {len(state['meta_knowledge'].get('best_practices', []))}")
```

## 六、总结

元学习与自适应是智能体技术的高级阶段，它们使智能体能够：

1. **快速适应新环境**：通过元学习，智能体能够从少量样本中快速学习
2. **持续自我改进**：通过持续学习，智能体能够不断积累知识和经验
3. **自主优化策略**：通过自我评估，智能体能够识别自身的优势和不足
4. **应对复杂场景**：通过整合多种学习策略，智能体能够应对各种复杂场景

通过本文的学习，你应该掌握：

- **元学习的基本概念**：了解不同类型的元学习方法
- **自适应的实现机制**：掌握智能体如何根据环境调整行为
- **持续学习的策略**：学习如何实现智能体的终身学习能力
- **自我评估的方法**：了解智能体如何评估自身表现
- **完整系统的构建**：掌握如何构建一个自适应智能体系统

这些技术将帮助你构建更智能、更灵活、更可靠的智能体系统，为用户提供更好的服务和体验。随着技术的不断发展，元学习与自适应将成为智能体技术的核心竞争力，为人工智能的发展开辟新的可能性。